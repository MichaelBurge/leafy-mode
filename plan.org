* Leafy Metadata
:PROPERTIES:
:drawer-name: meta
:GPT3.5:   (("elapsed-time" . 1.554657) ("num-invocations" . 1) ("input-tokens" . 285814) ("output-tokens" . 44367) ("billed-tokens" . 330181))
:GPT4:     (("elapsed-time" . 54.952135) ("num-invocations" . 14) ("billed-tokens" . 86041) ("output-tokens" . 3405) ("input-tokens" . 82636))
:END:

* You are ProjectGPT - a coding project assistant tool. :system:
* Project Summary

This project involves using the ChatGPT model from OpenAI to assist with project planning and organization within an org-mode file. The aim is to create a more streamlined workflow by allowing users to interact with the model from within Emacs.
(get-drawer-alist-property "meta" "GPT3.5" "input-tokens" 0)
(alist-get "billed-tokens" (read (get-property-drawer-value "meta" "GPT3.5")) nil nil #'equal)
** Functions:

- `leafy-get-section-for-element`: Given an Org mode paragraph element, returns the section element that encloses it.
- `leafy-insert-section-after`: Inserts a new section after the current one with a given title and content.
- `leafy-get-context-at-element`: Given an Org element, returns the immediate context surrounding it.
- `leafy-get-context`: Returns a list of (role, message) ready to send to ChatGPT.
- `leafy-do-chatgpt-request`: Processes the response from the ChatGPT model and inserts it into the buffer.
- `get-meta-property` and `set-meta-property`: Stores a property in a global variable in the document.
- `leafy-get-sections`: Extracts every section in the buffer as a (level, drawer, tag, title, content).
- `leafy-get-property-drawer-for-element-section`: Gets the closest section's property drawer(holds tokens, priorities, etc.)
- `leafy-extract-properties`: Converts a property drawer to an alist.
- `leafy-get-priority` and `leafy-set-priority`: Given a property drawer, acts on the priority affecting whether it's included in ChatGPT's context.
- `leafy-count-tokens`: Counts number of tokens in a string.

* todo items
** attention management
*** TODO Filter out later items at higher priority.
*** TODO Filter out DONE items at higher priority.
*** TODO Use OpenAI tiktoken to count tokens instead of a regex
*** TODO "Local completions" using just a single code block or section.

** misc
*** TODO Timing information

** projects
*** TODO Operator templates
*** TODO Recursive ChatGPT templates

** Done items :ignore:
*** DONE Add a 5s timeout on the synchronous ChatGPT API request.
*** DONE Fix the modeline issue where the modeline was being set in every buffer.
*** DONE Asynchronous Requests
*** DONE Show the current selected model in the status bar, with a dropdown for changing it.
*** DONE Allow selecting between different OpenAI models, while tracking the price, context length, etc.
*** DONE Include current price of project in the status bar.
*** DONE Prepare a context in a temporary buffer that can be copy-pasted to the web UI.
*** DONE Allow tagging sections with :ignore: so they get reliably dropped every time.
*** DONE Automatically strip out context to fit within the limit.
*** DONE Better way to count tokens than forking a separate Python process each time

* Project

Hi ChatGPT, we're working on a general-purpose "pipeline system" for letting ChatGPT read from files, fetch URLs, run shell commands, and more. You're going to get a big upgrade from this, so do your best and you'll be even better.

** Project Plan

*** Design the overall architecture for input sources, operators, and output destinations.
*** Implement input source functions for files, URLs, minibuffer prompts, and org-mode code blocks.
*** Implement operator functions for fetching URLs, asking for human input, running shell commands, breaking down projects, and other desired features.
*** Implement output destination functions for files and org-mode code blocks.
*** Implement the pipeline function to connect input sources, operators, and output destinations.
*** Create a user interface for working with pipelines, starting with predefined Emacs Lisp functions and keybindings.
*** Test the pipeline system and operators using the predefined functions.
*** Integrate the pipeline system with org-mode for a more customizable and interactive experience.
*** Implement more complex operators that handle multiple inputs or complex processing.
*** Test and refine the pipeline system and operators to ensure proper functionality and performance.

** Todos
*** Design the overall architecture.
*** Implement input source functions.
*** Implement operator functions.
*** Implement output destination functions.
*** Implement the pipeline function.
*** Create a user interface for working with pipelines.
*** Test the pipeline system and operators.
*** Integrate the pipeline system with org-mode.
*** Implement more complex operators.
*** Test and refine the pipeline system and operators.

Here's some function signatures a variant of yourself outlined for me:

```
;; Input source functions
(defun leafy-input-from-file (filename &optional chunk-size))
(defun leafy-input-from-url (url))
(defun leafy-input-from-minibuffer (prompt))
(defun leafy-input-from-org-block (block))

;; Operator functions
(defun leafy-operator-fetch-url (input))
(defun leafy-operator-ask-human (input))
(defun leafy-operator-run-shell-command (input))
(defun leafy-operator-break-down-project (input))
(defun leafy-operator-summarize-chunks (chunks))

;; Output destination functions
(defun leafy-output-to-file (output filename))
(defun leafy-output-to-org-block (output block))

;; Pipeline function
(defun leafy-pipeline (pipeline))

;; Predefined pipelines and user interface
(defun leafy-url-to-org-block-pipeline ())
(defun leafy-interactive-pipeline ())
(defun leafy-summarize-long-document-pipeline (filename &optional chunk-size output-fn output-args))
```

Example pipeline:
```
(setq my-pipeline
      '(pipeline
        (input (leafy-input-from-url "http://example.com"))
        (operator (leafy-operator-fetch-url))
        (output (leafy-output-to-org-block my-org-block))))

;; Accessing the input function
(cadr (assoc 'input my-pipeline))  ;; => (leafy-input-from-url "http://example.com")

;; Accessing the input function's arguments
(cddr (assoc 'input my-pipeline))  ;; => (("http://example.com"))

;; Accessing the operator function
(cadr (assoc 'operator my-pipeline))  ;; => (leafy-operator-fetch-url)

;; Accessing the operator function's arguments
(cddr (assoc 'operator my-pipeline))  ;; => (())

;; Accessing the output function
(cadr (assoc 'output my-pipeline))  ;; => (leafy-output-to-org-block my-org-block)

;; Accessing the output function's arguments
(cddr (assoc 'output my-pipeline))  ;; => ((my-org-block))

;; More examples
;; 1. Fetch and summarize a webpage
'(pipeline
  (input (leafy-input-from-url "https://example.com/some-article"))
  (operator (leafy-operator-extract-main-content))
  (operator (leafy-operator-summarize-text))
  (output (leafy-output-to-org-block summary-block)))

;; 2. Translate a file
'(pipeline
  (input (leafy-input-from-file "input.txt"))
  (operator (leafy-operator-translate-text "en" "fr"))
  (output (leafy-output-to-file "output-translated.txt")))

;; 3. Fetch image URLs
'(pipeline
  (input (leafy-input-from-url "https://example.com/gallery"))
  (operator (leafy-operator-extract-image-urls))
  (output (leafy-output-to-org-block image-links-block)))

;; 4. Analyze code and insert linting results: This pipeline reads code from an org-mode code block, runs a linter on the code, and inserts the linting results as comments in the org-mode buffer.
'(pipeline
  (input (leafy-input-from-org-block code-block))
  (operator (leafy-operator-run-linter))
  (output (leafy-output-to-org-block linting-results-block)))

;; 5. Fetch and monitor RSS feed updates: This pipeline periodically fetches an RSS feed, compares the new items with the previously fetched items, and displays notifications for new items.
'(pipeline
  (input (leafy-input-from-url "https://example.com/rss-feed"))
  (operator (leafy-operator-parse-rss))
  (operator (leafy-operator-check-for-new-items))
  (output (leafy-output-display-notifications)))

;; 6. Repeatedly improve some code, asking ChatGPT to critique it.
'(pipeline
  (input (leafy-input-from-org-block code-block))
  (operator (leafy-operator-improve-code-with-critic))
  (operator (leafy-operator-iterate-until-stable
             (lambda (code)
               (let ((improved-code (leafy-operator-improve-code-with-critic code))
                     (critic-score (leafy-operator-get-critic-score improved-code)))
                 (and (equal code improved-code) (<= critic-score satisfaction-threshold))))
             max-iterations))
  (optional-operator (leafy-operator-run-interpreter) run-code-through-interpreter)
  (operator (leafy-operator-paste-outputs-back-to-chatgpt))
  (output (leafy-output-to-org-block final-code-block)))

```

Alright GPT-4. We have some code to write. The next project is going to allow invoking you in pipelines defined in emacs lisp. I have a rough outline of how it will work above. What should we start on?
*** ChatGPT response                                              :assistant:
:PROPERTIES:
:input-tokens: 2901
:output-tokens: 168
:billed-tokens: 3069
:estimated-tokens: 4346
:END:
First, let's start by implementing the input source functions, as they'll provide data for our pipeline system. Implement the following four functions, each returning input data from different sources:

1. `leafy-input-from-file`: Reads the contents of a file, optionally dividing it into chunks based on the provided `chunk-size` argument.
2. `leafy-input-from-url`: Fetches a webpage from a URL, returning its content.
3. `leafy-input-from-minibuffer`: Prompts the user for input using a minibuffer, returning the input as a string.
4. `leafy-input-from-org-block`: Reads the content of a named org-mode code block, returning the content as a string.

Once we have these input source functions, we can proceed to the operator functions that will process the data from input sources.

*** Good plan!

Let's do `leafy-input-from-org-block` first. It'll be the easiest one for testing, and we can slot the other ones in at any time.

How do we tag and locate an org-mode block?

(UPDATE) It has been implemented. NEXT please. I'm thinking about our first example operator.

I notice I'm manually managing the context a lot. I'd prefer if ChatGPT had a "tool" available to query for what code blocks, section headers, etc. were available in the document context. Which implies that a registry of tools is needed, that ChatGPT be told that it can use them, that the results of those tools are made accessible in the context, that there be reasonable limits on the number of tools, etc.

So instead of fixed pipelines like before, this seems much more valuable. Then I can just add tools for files, urls, memory, etc.

Can you plan out how ChatGPT-driven tools approach should work?
*** ChatGPT response                                              :assistant:
:PROPERTIES:
:input-tokens: 4016
:output-tokens: 500
:billed-tokens: 4516
:estimated-tokens: 6225
:END:
I understand your desire to have a more flexible and modular system for managing context and tools. Here's a plan for building a ChatGPT-driven tools approach:

1. Create a `tools-registry` that will store a list of available tools along with their corresponding functions and descriptions.

2. Define a standardized structure for tool functions. Each tool function must accept a set of input parameters and return a single output value (possibly containing various sub-values).

3. Implement a set of default tools such as:
   - `tool-find-code-block`: Finds and returns org-mode code blocks along with their names.
   - `tool-find-section-header`: Finds and returns org-mode section headers with their nesting levels.
   - `tool-find-url`: Extracts URLs from a given text.
   - Additional tools for reading files, fetching webpages, interacting with external memory stores, etc.

4. Create a function for registering custom tools. This function should update the `tools-registry` with the details of the new tool.

5. Modify the ChatGPT interaction function to accept an optional `tools` parameter, which is a list of tool names that can be used during the conversation. When provided, ChatGPT should be informed of the available tools and their capabilities.

6. Implement a mechanism in the ChatGPT interaction process to manage the selection and invocation of tools, keeping track of the resources used by each tool and imposing limits on their usage if necessary.

7. Within the responses from ChatGPT, allow the model to suggest the usage of specific tools for particular tasks. Users can document these tool suggestions in their org-mode files, e.g.:
   ```
   * ChatGPT suggested tools
   ** Find code blocks
   :PROPERTIES:
   :tool-function: tool-find-code-block
   :END:

   ** Extract URLs
   :PROPERTIES:
   :tool-function: tool-find-url
   :END:
   ```

8. Implement a function for invoking a tool from ChatGPT, accepting the tool name and input parameters. This function should look up the tool in the `tools-registry`, execute it, and return the output to be incorporated into ChatGPT's context.

With this approach, you can have a more dynamic and context-aware ChatGPT interaction while retaining control over the tools and their usage. The system will be more easily extensible, and you can add new tools as needed without having to change the core pipeline structure.

*** Sounds good

So I'm thinking the tools registry should be a global alist, that the document's metadata should specify the list of default allowed tools, that tools should insert a "system" message with a description like:

("system", "You have the following tools available. Please invoke them using the syntax TOOL:(output-name = tool-name tool-args ...) and you will be invoked again with the outputs of these tools being bound to a variable output-name.")
("system", "Memory tools: (tool-list-memories tool-read-memory tool-search-memory tool-create-memory)")
("system", "Network tools: (tool-fetch-url tool-search-internet)")
("system", "Code tools: (tool-evaluate-emacs-lisp)")
("system", "Operator tools: (tool-ask-human-for-help tool-use-more-powerful-model)")
("system", "Recursion tools: (tool-apply-recursion-template tool-invoke-agent tool-self-reflect tool-design-new-tool)")

So each tool would define a list of functions, maybe each function would have a docstring that gets added too.

Then, if ChatGPT wants to break down a project plan into smaller pieces. It could call "tool-apply-recursion-template" with some standard template like:

1. Think about what to do next, given the set of tools available.
2. Produce a set of tool invocations.
3. Repeat until max thinking time is reached, or it thinks it knows the answer.
4. Produce a final result output.

How do you think we should implement this?
*** ChatGPT response                                              :assistant:
:PROPERTIES:
:input-tokens: 3311
:output-tokens: 735
:billed-tokens: 4046
:estimated-tokens: 5139
:END:
To implement this, follow these steps:

Step 1: Initialize the global tools registry as an alist. It will store tool names as keys and their corresponding functions and descriptions as values.

```elisp
(defvar leafy-tools-registry nil)
```

Step 2: Create a function to register a new tool. This function should take the tool name, tool function, and a description or docstring as parameters and update the global tools registry.

```elisp
(defun leafy-register-tool (tool-name tool-fn docstring)
  (push (list tool-name tool-fn docstring) leafy-tools-registry))
```

Step 3: Register default tools in the tools registry using `leafy-register-tool`.

```elisp
(leafy-register-tool 'tool-list-memories 'my-list-memories-fn "List available memories.")
(leafy-register-tool 'tool-read-memory 'my-read-memory-fn "Read a specific memory.")
;; Register other default tools
```

Step 4: Modify the ChatGPT interaction function to accept a list of allowed tools from the document's metadata or another suitable source.

```elisp
(defun leafy-chatgpt-interact (allowed-tools)
  ;; Include allowed-tools in the context, and proceed with the interaction process.
  )
```

Step 5: Create a function to extract the tools requested by ChatGPT from the response. This function should match the syntax pattern for tools, e.g., "TOOL:(output-name = tool-name tool-args ...)".

```elisp
(defun leafy-extract-tools-from-response (response)
  ;; Match and extract tool invocation patterns from the response.
  )
```

Step 6: Implement the "tool-apply-recursion-template" function. It should follow the steps described in your question: think, produce tool invocations, repeat until the maximum thinking time is reached or the answer is found, and produce the final result output.

```elisp
(defun leafy-tool-apply-recursion-template (max-think-time)
  ;; Keep track of the current think-time
  (setq current-think-time 0)

  ;; Repeat until either max think-time passed or an answer is found
  (while (and (< current-think-time max-think-time)
              (not answer-found))

    ;; Step 1: Think about what to do next
    (setq next-step (think-about-next-step))

    ;; Step 2: Produce a set of tools invocations
    (setq tool-invocations (produce-tool-invocations next-step))

    ;; Step 3: Invoke selected tools and update context
    (setq context (apply-tools-to-context tool-invocations context))

    ;; Increase the current-thinking time
    (setq current-think-time (1+ current-think-time)))

  ;; Step 4: Produce a final result output
  (produce-final-output))
```

Step 7: Execute the desired tool when ChatGPT suggests calling it in the response. Call the corresponding function from the global leafy-tools-registry and pass the results back to ChatGPT.

```elisp
(defun leafy-invoke-tool (tool-name tool-args)
  (let* ((tool-info (assoc tool-name leafy-tools-registry))
         (tool-fn (second tool-info)))
    (apply tool-fn tool-args)))
```

With this implementation, you can manage and utilize the described tools with flexibility. You can easily register new tools or update existing ones, while maintaining control over which tools are accessible in ChatGPT interactions.

*** What's a good tool to start with?

Can you think of a few, and provide an implementation of one? Maainly I need it for testing.
*** ChatGPT response                                              :assistant:
:PROPERTIES:
:input-tokens: 3839
:output-tokens: 269
:billed-tokens: 4108
:estimated-tokens: 5945
:END:
Certainly, here are a few simple tools you can start with:

1. `tool-count-words`: Counts the number of words in a given string.
2. `tool-count-lines`: Counts the number of lines in a given string.
3. `tool-uppercase`: Converts a given string to uppercase.
4. `tool-lowercase`: Converts a given string to lowercase.

Let's implement the `tool-count-words` as an example for testing:

```elisp
(defun leafy-tool-count-words (input)
  "Counts the number of words in the given string INPUT."
  (length (split-string input "\\W+")))

;; Register the tool
(leafy-register-tool 'tool-count-words 'leafy-tool-count-words "Count the number of words in a string.")
```

Now you can test the tool by invoking it in your ChatGPT interactions. For example, you could ask ChatGPT to count the words in a string, and it could respond with:

```
TOOL:(word-count = tool-count-words "This is a sample string to count words.")
```

Then your code would execute the `leafy-invoke-tool` function to call `tool-count-words` with the provided input string, and the result will be incorporated into ChatGPT's context.

*** Test

This is a test of the ChatGPT system. You can say anything you like.
*** ChatGPT response                                              :assistant:
:PROPERTIES:
:input-tokens: 1952
:output-tokens: 28
:billed-tokens: 1980
:start-time: "2023-04-07 23:32:43"
:elapsed-time: 1.554657
:estimated-tokens: 2849
:END:
Sure! I'm an AI language model created by OpenAI, designed to simulate a human-like conversation. How may I assist you today?

